{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "make_classif_40_20_qda98boosting98_logreg78_probablyNonMonotonicFeaturesCauseGinihighFor10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chervov/Test01/blob/master/make_classif_40_20_qda98boosting98_logreg78_probablyNonMonotonicFeaturesCauseGinihighFor10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAQh5AlPlpmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.ensemble import  RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import sklearn.datasets\n",
        "from sklearn.model_selection import cross_val_score,train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhnM_E10pn5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = sklearn.datasets.make_classification(n_samples=10000, n_features=40, n_informative=20, n_redundant=0, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=0)\n",
        "X = pd.DataFrame(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWVtkOkYpucj",
        "colab_type": "code",
        "outputId": "f4d1066b-609a-4c03-e85e-66fb03ab25fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "random_state = 0\n",
        "X_train,X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, stratify = y, random_state = random_state)\n",
        "def Gin(y,v):\n",
        "  r = roc_auc_score(y,v)\n",
        "  g = 100 * ( 2*r-1 )\n",
        "  return g\n",
        "\n",
        "df_feature_report = pd.DataFrame()\n",
        "for f in X.columns:\n",
        "  df_feature_report.loc[f,'Gin'] = Gin(y,X[f])\n",
        "  df_feature_report.loc[f,'Gin Abs'] = np.abs( Gin(y,X[f]) )\n",
        "  df_feature_report.loc[f,'Gin Train'] = Gin(y_train,X_train[f])  \n",
        "  df_feature_report.loc[f,'Gin Test'] = Gin(y_test,X_test[f])  \n",
        "  \n",
        "df_feature_report = df_feature_report.sort_values('Gin Abs', ascending = False)\n",
        "df_feature_report = df_feature_report.reset_index()\n",
        "df_feature_report"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Gin</th>\n",
              "      <th>Gin Abs</th>\n",
              "      <th>Gin Train</th>\n",
              "      <th>Gin Test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21</td>\n",
              "      <td>-44.741057</td>\n",
              "      <td>44.741057</td>\n",
              "      <td>-43.631061</td>\n",
              "      <td>-47.278928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14</td>\n",
              "      <td>22.476818</td>\n",
              "      <td>22.476818</td>\n",
              "      <td>22.732139</td>\n",
              "      <td>21.908661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19</td>\n",
              "      <td>-21.439929</td>\n",
              "      <td>21.439929</td>\n",
              "      <td>-20.882277</td>\n",
              "      <td>-22.701463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12</td>\n",
              "      <td>20.727137</td>\n",
              "      <td>20.727137</td>\n",
              "      <td>21.399648</td>\n",
              "      <td>19.158345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>-20.549009</td>\n",
              "      <td>20.549009</td>\n",
              "      <td>-20.953248</td>\n",
              "      <td>-19.625013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>37</td>\n",
              "      <td>-20.375328</td>\n",
              "      <td>20.375328</td>\n",
              "      <td>-22.449102</td>\n",
              "      <td>-15.590428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>35</td>\n",
              "      <td>-20.364600</td>\n",
              "      <td>20.364600</td>\n",
              "      <td>-20.548513</td>\n",
              "      <td>-19.984302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>31</td>\n",
              "      <td>-20.160680</td>\n",
              "      <td>20.160680</td>\n",
              "      <td>-19.081410</td>\n",
              "      <td>-22.738885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>38</td>\n",
              "      <td>20.081416</td>\n",
              "      <td>20.081416</td>\n",
              "      <td>17.454503</td>\n",
              "      <td>26.211602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>5</td>\n",
              "      <td>-19.897584</td>\n",
              "      <td>19.897584</td>\n",
              "      <td>-20.983746</td>\n",
              "      <td>-17.381809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>8</td>\n",
              "      <td>19.526304</td>\n",
              "      <td>19.526304</td>\n",
              "      <td>19.420937</td>\n",
              "      <td>19.678791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>6</td>\n",
              "      <td>-2.444046</td>\n",
              "      <td>2.444046</td>\n",
              "      <td>-3.230835</td>\n",
              "      <td>-0.632979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>18</td>\n",
              "      <td>2.326502</td>\n",
              "      <td>2.326502</td>\n",
              "      <td>1.981773</td>\n",
              "      <td>3.166406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.893574</td>\n",
              "      <td>1.893574</td>\n",
              "      <td>-1.812858</td>\n",
              "      <td>-2.009781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>20</td>\n",
              "      <td>1.810710</td>\n",
              "      <td>1.810710</td>\n",
              "      <td>2.260565</td>\n",
              "      <td>0.737868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>24</td>\n",
              "      <td>-1.733598</td>\n",
              "      <td>1.733598</td>\n",
              "      <td>-1.650475</td>\n",
              "      <td>-1.890848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>34</td>\n",
              "      <td>1.701606</td>\n",
              "      <td>1.701606</td>\n",
              "      <td>1.171829</td>\n",
              "      <td>2.946939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>27</td>\n",
              "      <td>-1.518366</td>\n",
              "      <td>1.518366</td>\n",
              "      <td>-1.707520</td>\n",
              "      <td>-1.113869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>33</td>\n",
              "      <td>-0.995837</td>\n",
              "      <td>0.995837</td>\n",
              "      <td>-1.740924</td>\n",
              "      <td>0.758668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>7</td>\n",
              "      <td>-0.955917</td>\n",
              "      <td>0.955917</td>\n",
              "      <td>-1.729528</td>\n",
              "      <td>0.871379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>11</td>\n",
              "      <td>0.803221</td>\n",
              "      <td>0.803221</td>\n",
              "      <td>2.200108</td>\n",
              "      <td>-2.467382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>28</td>\n",
              "      <td>0.778653</td>\n",
              "      <td>0.778653</td>\n",
              "      <td>2.190165</td>\n",
              "      <td>-2.472004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>17</td>\n",
              "      <td>0.774173</td>\n",
              "      <td>0.774173</td>\n",
              "      <td>1.322474</td>\n",
              "      <td>-0.452356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>13</td>\n",
              "      <td>0.733101</td>\n",
              "      <td>0.733101</td>\n",
              "      <td>2.045071</td>\n",
              "      <td>-2.277782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>4</td>\n",
              "      <td>-0.722421</td>\n",
              "      <td>0.722421</td>\n",
              "      <td>-1.370670</td>\n",
              "      <td>0.842668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>39</td>\n",
              "      <td>0.636765</td>\n",
              "      <td>0.636765</td>\n",
              "      <td>0.313821</td>\n",
              "      <td>1.417958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.565733</td>\n",
              "      <td>0.565733</td>\n",
              "      <td>0.548760</td>\n",
              "      <td>-3.203383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>26</td>\n",
              "      <td>0.549077</td>\n",
              "      <td>0.549077</td>\n",
              "      <td>0.054947</td>\n",
              "      <td>1.673514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>32</td>\n",
              "      <td>-0.540581</td>\n",
              "      <td>0.540581</td>\n",
              "      <td>-0.259029</td>\n",
              "      <td>-1.232802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>10</td>\n",
              "      <td>0.532509</td>\n",
              "      <td>0.532509</td>\n",
              "      <td>0.130604</td>\n",
              "      <td>1.511647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>25</td>\n",
              "      <td>0.491404</td>\n",
              "      <td>0.491404</td>\n",
              "      <td>-0.235388</td>\n",
              "      <td>2.232626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.488284</td>\n",
              "      <td>0.488284</td>\n",
              "      <td>-2.256891</td>\n",
              "      <td>3.613695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>36</td>\n",
              "      <td>-0.405404</td>\n",
              "      <td>0.405404</td>\n",
              "      <td>-1.960989</td>\n",
              "      <td>3.186406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>16</td>\n",
              "      <td>0.342988</td>\n",
              "      <td>0.342988</td>\n",
              "      <td>0.273266</td>\n",
              "      <td>0.520356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>30</td>\n",
              "      <td>0.302556</td>\n",
              "      <td>0.302556</td>\n",
              "      <td>-0.536286</td>\n",
              "      <td>2.323204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>9</td>\n",
              "      <td>-0.252572</td>\n",
              "      <td>0.252572</td>\n",
              "      <td>0.755584</td>\n",
              "      <td>-2.616805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>15</td>\n",
              "      <td>0.132660</td>\n",
              "      <td>0.132660</td>\n",
              "      <td>1.392434</td>\n",
              "      <td>-2.743916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>22</td>\n",
              "      <td>-0.089556</td>\n",
              "      <td>0.089556</td>\n",
              "      <td>-0.212825</td>\n",
              "      <td>0.231645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>29</td>\n",
              "      <td>-0.079020</td>\n",
              "      <td>0.079020</td>\n",
              "      <td>-0.209723</td>\n",
              "      <td>0.223734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>23</td>\n",
              "      <td>-0.009500</td>\n",
              "      <td>0.009500</td>\n",
              "      <td>-0.192237</td>\n",
              "      <td>0.449423</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    index        Gin    Gin Abs  Gin Train   Gin Test\n",
              "0      21 -44.741057  44.741057 -43.631061 -47.278928\n",
              "1      14  22.476818  22.476818  22.732139  21.908661\n",
              "2      19 -21.439929  21.439929 -20.882277 -22.701463\n",
              "3      12  20.727137  20.727137  21.399648  19.158345\n",
              "4       3 -20.549009  20.549009 -20.953248 -19.625013\n",
              "5      37 -20.375328  20.375328 -22.449102 -15.590428\n",
              "6      35 -20.364600  20.364600 -20.548513 -19.984302\n",
              "7      31 -20.160680  20.160680 -19.081410 -22.738885\n",
              "8      38  20.081416  20.081416  17.454503  26.211602\n",
              "9       5 -19.897584  19.897584 -20.983746 -17.381809\n",
              "10      8  19.526304  19.526304  19.420937  19.678791\n",
              "11      6  -2.444046   2.444046  -3.230835  -0.632979\n",
              "12     18   2.326502   2.326502   1.981773   3.166406\n",
              "13      1  -1.893574   1.893574  -1.812858  -2.009781\n",
              "14     20   1.810710   1.810710   2.260565   0.737868\n",
              "15     24  -1.733598   1.733598  -1.650475  -1.890848\n",
              "16     34   1.701606   1.701606   1.171829   2.946939\n",
              "17     27  -1.518366   1.518366  -1.707520  -1.113869\n",
              "18     33  -0.995837   0.995837  -1.740924   0.758668\n",
              "19      7  -0.955917   0.955917  -1.729528   0.871379\n",
              "20     11   0.803221   0.803221   2.200108  -2.467382\n",
              "21     28   0.778653   0.778653   2.190165  -2.472004\n",
              "22     17   0.774173   0.774173   1.322474  -0.452356\n",
              "23     13   0.733101   0.733101   2.045071  -2.277782\n",
              "24      4  -0.722421   0.722421  -1.370670   0.842668\n",
              "25     39   0.636765   0.636765   0.313821   1.417958\n",
              "26      2  -0.565733   0.565733   0.548760  -3.203383\n",
              "27     26   0.549077   0.549077   0.054947   1.673514\n",
              "28     32  -0.540581   0.540581  -0.259029  -1.232802\n",
              "29     10   0.532509   0.532509   0.130604   1.511647\n",
              "30     25   0.491404   0.491404  -0.235388   2.232626\n",
              "31      0  -0.488284   0.488284  -2.256891   3.613695\n",
              "32     36  -0.405404   0.405404  -1.960989   3.186406\n",
              "33     16   0.342988   0.342988   0.273266   0.520356\n",
              "34     30   0.302556   0.302556  -0.536286   2.323204\n",
              "35      9  -0.252572   0.252572   0.755584  -2.616805\n",
              "36     15   0.132660   0.132660   1.392434  -2.743916\n",
              "37     22  -0.089556   0.089556  -0.212825   0.231645\n",
              "38     29  -0.079020   0.079020  -0.209723   0.223734\n",
              "39     23  -0.009500   0.009500  -0.192237   0.449423"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2GnaMaRqRgY",
        "colab_type": "code",
        "outputId": "c96f0312-8ac4-4245-e1f5-a6ee390126fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "\n",
        "\n",
        "# md = QuadraticDiscriminantAnalysis() # LogisticRegression(solver = 'liblinear')\n",
        "l_f = X.columns\n",
        "md = LogisticRegression(solver = 'liblinear', penalty = 'l1', C=0.05)\n",
        "\n",
        "md.fit(X_train[l_f],y_train)\n",
        "p = md.predict_proba(X_train[l_f])[:,1]\n",
        "g = Gin(y_train,p)\n",
        "print(g)\n",
        "p = md.predict_proba(X_test[l_f])[:,1]\n",
        "g = Gin(y_test,p)\n",
        "print(g)\n",
        "print(md.coef_)\n",
        "print((md.coef_!=0).sum())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79.28937253913084\n",
            "78.63160645618925\n",
            "[[-0.05833174 -0.04163186  0.01449751 -0.14856399  0.         -0.17559983\n",
            "   0.09949493  0.10354661  0.26710137  0.          0.          0.03727909\n",
            "   0.34787194 -0.068156    0.24137945  0.01908755  0.          0.\n",
            "   0.         -0.03405973  0.         -0.47724282  0.         -0.03206529\n",
            "   0.02604394  0.          0.         -0.11398062  0.          0.\n",
            "   0.         -0.09083384  0.         -0.08124459 -0.03808006 -0.20442835\n",
            "   0.04900678 -0.35941179  0.27954162  0.        ]]\n",
            "25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6yNXvS8tk54",
        "colab_type": "code",
        "outputId": "2bf73882-ac88-4e35-880c-fb6327faba5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "\n",
        "\n",
        "# md = QuadraticDiscriminantAnalysis() # LogisticRegression(solver = 'liblinear')\n",
        "l_f = X.columns\n",
        "md = LogisticRegressionCV(solver = 'liblinear', penalty = 'l1', scoring = 'roc_auc')# , C=0.05)\n",
        "\n",
        "md.fit(X_train[l_f],y_train)\n",
        "p = md.predict_proba(X_train[l_f])[:,1]\n",
        "g = Gin(y_train,p)\n",
        "print(g)\n",
        "p = md.predict_proba(X_test[l_f])[:,1]\n",
        "g = Gin(y_test,p)\n",
        "print(g)\n",
        "print(md.coef_)\n",
        "print((md.coef_!=0).sum())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "79.28553580161815\n",
            "78.63391757140903\n",
            "[[-0.05654859 -0.04001269  0.01300409 -0.14790028  0.         -0.17483558\n",
            "   0.09902107  0.10296339  0.26652664  0.          0.          0.03681454\n",
            "   0.34664836 -0.06786945  0.2407638   0.01747482  0.          0.\n",
            "   0.         -0.03387723  0.         -0.47596974  0.         -0.03021019\n",
            "   0.02564142  0.          0.         -0.11335178  0.          0.\n",
            "   0.         -0.09086138  0.         -0.08086546 -0.03804709 -0.20387778\n",
            "   0.04840424 -0.35805124  0.2782233   0.        ]]\n",
            "25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uTgZ3VVrppc",
        "colab_type": "code",
        "outputId": "eb6ce6f8-0850-4aac-c123-7f8fa3dd95a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "md = QuadraticDiscriminantAnalysis() # LogisticRegression(solver = 'liblinear')\n",
        "l_f = X.columns\n",
        "#md = LogisticRegression(solver = 'liblinear', penalty = 'l1', C=0.1)\n",
        "\n",
        "md.fit(X_train[l_f],y_train)\n",
        "p = md.predict_proba(X_train[l_f])[:,1]\n",
        "g = Gin(y_train,p)\n",
        "print(g)\n",
        "p = md.predict_proba(X_test[l_f])[:,1]\n",
        "g = Gin(y_test,p)\n",
        "print(g)\n",
        "#print(md.coef_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98.3929620846252\n",
            "98.30088586824152\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Unsu56LvsSdi",
        "colab_type": "code",
        "outputId": "4a8634ee-ae65-48c4-fee9-ddfc7695769b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import lightgbm as lgb\n",
        "md = lgb.LGBMClassifier(n_estimators = 1000) # LogisticRegression(solver = 'liblinear')\n",
        "md.fit(X_train,y_train)\n",
        "p = md.predict_proba(X_train)[:,1]\n",
        "g = Gin(y_train,p)\n",
        "print(g)\n",
        "p = md.predict_proba(X_test)[:,1]\n",
        "g = Gin(y_test,p)\n",
        "print(g)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100.0\n",
            "98.16701896358926\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W0fOMbNsi5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}